from PIL import Image as im
import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets, layers, Sequential, models
from keras.datasets import mnist
import numpy as np

train_data_points = 1600
test_data_points = 300
total_data_points = train_data_points + test_data_points
pixels = 32
bins = 62

images = []
inPath = "C:/NN/NIST SD 19/DataSet/"
i = 0
for i in range(48, 123):
    print(i)
    for j in range(total_data_points):
        if 47 < i < 58 or 64 < i < 91 or 96 < i < 123:
            input_path = inPath + str(i) + '-' + str(j) + '.png'
            img = im.open(input_path)
            img = img.convert('1')
            img = img.resize((pixels, pixels))
            img_array = np.asarray(img)
            images.append(img_array)
            img.close()

images_array = np.reshape(images, (bins, total_data_points, pixels, pixels))

training_data = images_array[:, 0:train_data_points, :, :]
training_data = np.reshape(training_data, (train_data_points * bins, pixels, pixels, 1))

test_data = images_array[:, train_data_points:total_data_points, :, :]
test_data = np.reshape(test_data, (test_data_points * bins, pixels, pixels, 1))

training_labels = np.empty(0)
test_labels = np.empty(0)
for i in range(bins):
    to_add = i * np.ones(train_data_points)
    training_labels = np.append(training_labels, to_add)
    to_add = i * np.ones(test_data_points)
    test_labels = np.append(test_labels, to_add)

# print(test_labels[3676])
# im.fromarray(test_data[3676]).show()

training_data = training_data / 255
test_data = test_data / 255

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(62))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(training_data, training_labels, epochs=4,
                    validation_data=(test_data, test_labels))

test_loss, test_acc = model.evaluate(test_data, test_labels, verbose=2)
print(str(test_acc * 100) + "  %")


# model = Sequential([
#     layers.Flatten(input_shape=(pixels, pixels)),
#     layers.Dense(750, activation='relu'),
#     layers.Dense(bins, activation='softmax')
# ])
#
# model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
#
# history = model.fit(training_data, training_labels, epochs=4,
#                     validation_data=(test_data, test_labels))
#
# test_loss, test_acc = model.evaluate(test_data,  test_labels, verbose=2)
# print(str(test_acc * 100) + "  %")
